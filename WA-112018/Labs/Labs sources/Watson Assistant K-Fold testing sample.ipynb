{"nbformat_minor": 2, "cells": [{"source": "# K-Fold testing and Confusion Matrix of a Watson Assistant workspace.\n\nThis example notebook is used to show you how to generate a K-fold test in Watson Assistant, and run the cross validation test. \n\nIt demonstrates a technique to programmatically train and evaluate the intent recognition performance for a workspace in <a href=\"https://www.ibm.com/watson/developercloud/assistant/api/v1/\" target=\"_blank\" rel=\"noopener noreferrer\">Watson Assistant</a>.\n\nAt a high level, intents are purposes or goals expressed in a user's input, such as answering a question or processing a bill payment. By recognizing the intent expressed in a customer's input, the Assistant service can choose the correct dialog flow for responding to it.\n\nThis notebook will demonstrate how the Watson Assistant API can be directly accessed to programmatically train the workspace on intents. This is an alternative to the GUI tool typically used to train a workspace.\n\nBy managing the training process programmatically, the intent recognition performance can be reliably tested with a truly blind test set.\n\nThis notebook runs on Python 3.5\nSo, on the top right be sure to run the right Kernel, if not go to menu **Kernel > Change Kernel** then select **Python 3.5** \n\nTips:\n* Code cells are identifiable by their `In [ ]:` prefix in the margin\n* To execute the celsl in the notebook, select the cell and click the run button, or hit Ctrl-Enter.\n* Cells which have not been executed before will have empty brackets, while executed cells will have a sequence number within, e.g. `In [13]`\n* Cell execution result displays below the cell\n* To clear all exection statuses and outputs, use the `Cell/All Output/Clear` menu.\n\nThen execute the cell (Ctrl-Enter or run button)", "cell_type": "markdown", "metadata": {"run_control": {"frozen": true}, "deletable": false}}, {"source": "## Table of contents\n\n1. [Install and import packages](#setup)\n2. [Authenticate to the Watson Assistant Service](#authenticate)\n3. [Import the data as a pandas DataFrame](#import)\n4. [Generate Folds and split the data set for training and testing](#foldandsplit)\n5. [Create the workspaces](#workspaces)\n6. [Check workspace status](#status)\n7. [Run the test](#runtest)\n8. [Clean up](#clean)\n9. [Understanding the results you got](#understanding)\n10. [Building a confusion matrix](#matrix)<br>\n[Summary and next steps](#Summary-and-next-steps)", "cell_type": "markdown", "metadata": {}}, {"source": "## <a id=\"setup\"></a> Step 1. Install and import packages\n\nInstall and import the necessary packages.", "cell_type": "markdown", "metadata": {}}, {"source": "!pip install --upgrade watson_developer_cloud\n!pip install --upgrade numpy\n!pip install --upgrade pandas\n!pip install --upgrade scikit-learn\n!pip install --upgrade matplotlib", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": null}, {"source": "## <a id=\"authenticate\"></a>Step 2. Authenticate to the Watson Assistant\n\nSign up for the Watson Conversation service and enter your credentials. \n\n1. Sign up for [Watson Assistant](https://console.bluemix.net/catalog/services/conversation) in IBM Cloud.\n1. On your Watson Assistant service page, click **Service credentials**.\n1. Find your credentials. \n1. Add your workspace ID, username, and password to the next cell and run the cell.\n\nTips:\n* The Watson Studio and the Watson Assistant must be in the same IBM Cloud region (US South for instance)\n\n\nThe `ctx` object you get from the Conversation service credentials window. For this example you should create a new service for testing, as the test could generate 10 workspaces. \n\nYou have to set the language of your workspaces. This is a 2 digit language identifier. Check the <A HREF=\"https://console.bluemix.net/docs/services/conversation/lang-support.html#supported-languages\">supported languages</A> page for what codes can be used. \n\nThe `number_of_folds` is set to `5` so you can test this with a free conversation service. For production testing, you should set the `number_of_folds` to `10`. ", "cell_type": "markdown", "metadata": {"run_control": {"frozen": true}, "deletable": false}}, {"source": "ctx = {\n  \"url\": \"https://gateway.watsonplatform.net/conversation/api\",\n  \"apikey\": \"<API KEY>\"\n}\n\nlanguage = 'en'\nVERSION = '2018-07-10'\n\nnumber_of_folds = 5", "cell_type": "code", "metadata": {"ExecuteTime": {"start_time": "2017-12-03T06:34:00.938045Z", "end_time": "2017-12-03T06:34:00.942514Z"}, "deletable": false}, "outputs": [], "execution_count": null}, {"source": "#import pandas as pd\nimport numpy as np\nfrom watson_developer_cloud import AssistantV1\nfrom sklearn.model_selection import KFold\n\nconversation = AssistantV1( \n    iam_apikey=ctx.get('apikey'),\n    url=ctx.get('url'),\n    version=VERSION)", "cell_type": "code", "metadata": {"ExecuteTime": {"start_time": "2017-12-03T06:34:02.092375Z", "end_time": "2017-12-03T06:34:02.098244Z"}, "deletable": false}, "outputs": [], "execution_count": null}, {"source": "## <a id=\"import\"></a>Step 3. Import the data as a pandas DataFrame\n\nThe data consists of sample user questions and the assigned intents. \n\n**For notebooks running on IBM Data Science Experience:**\n\nTo get the data and load it into a pandas DataFrame:\n\n* Select the code cell below, and **delete all its content**\n* Open the data panel on the right using the 1001 button icon  (top right)\n* Drop your file with the your intents and user examples.\n* From the data panel on the right use context menu on the added file choose **Insert to code > Insert Pandas DataFrame** \n\nSome code should be generated, which creates a `df_data_1` panda DataFrame. If the name is different, change the variable name back to `df_data_1`\n\n**For Python notebook servers**\n1. Uncomment and modify the code stub to load data from your server's filesystem. ", "cell_type": "markdown", "metadata": {}}, {"source": "\nimport sys\nimport types\nimport pandas as pd\nfrom botocore.client import Config\nimport ibm_boto3\n\ndef __iter__(self): return 0\n\n# @hidden_cell\n# The following code accesses a file in your IBM Cloud Object Storage. It includes your credentials.\n# You might want to remove those credentials before you share your notebook.\nclient_93c7a4746f1e4132864e7ef0a2d31c48 = ibm_boto3.client(service_name='s3',\n<>\n# add missing __iter__ method, so pandas accepts body as file-like object\nif not hasattr(body, \"__iter__\"): body.__iter__ = types.MethodType( __iter__, body )\n\ndf_data_1 = pd.read_csv(body)\ndf_data_1.head()\n\n", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": null}, {"source": "Rename the DataFrame to `df`:", "cell_type": "markdown", "metadata": {}}, {"source": "# Make sure this uses the variable above. The number will vary in the inserted code.\ntry:\n    examples = df_data_1\nexcept NameError as e:\n    print('Error: Setup is incorrect or incomplete.\\n')\n    print('Follow the instructions to insert the pandas DataFrame above, and edit to')\n    print('make the generated df_data_# variable match the variable used here.')\n    raise", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": null}, {"source": "##  <a id=\"foldandsplit\"></a>Step 4. Generate Folds and split the data set for training and testing.\n\nWhat happens next is we randomise the questions, and split them evenly into `number_of_folds` buckets. ", "cell_type": "markdown", "metadata": {"run_control": {"frozen": true}, "deletable": false}}, {"source": "bucket = np.arange(len(examples))\nfolds = []\n\nkf = KFold(n_splits=number_of_folds, shuffle=True)\nfor train_index, test_index in kf.split(bucket):\n    train, test = bucket[train_index], bucket[test_index]\n    fold = { \n        'test': test,\n        'train': train\n    }\n    folds.append(fold)", "cell_type": "code", "metadata": {"ExecuteTime": {"start_time": "2017-12-03T06:34:07.089789Z", "end_time": "2017-12-03T06:34:07.098529Z"}, "editable": false, "deletable": false}, "outputs": [], "execution_count": null}, {"source": "Create intents for fold:\nThis method will go through CSV lines and create an `intents[]` object for when the workspace is created.\n", "cell_type": "markdown", "metadata": {"run_control": {"frozen": true}, "deletable": false}}, {"source": "def createIntents(train_list=None):\n    results = []\n    for i in train_list:\n        row = {}\n        question = examples.iloc[i]['example']\n        intent = examples.iloc[i]['intent']\n        \n        if not any(intent in x['intent'] for x in results):\n            row = { 'intent': intent, \n                    'examples': [ {'text': question } ] } \n        else:\n            row = [d for d in results if d.get('intent') == intent][0]\n            results[:] = [d for d in results if d.get('intent') != intent]\n            e = {'text': question}\n            row['examples'].append(e)\n            \n        results.append(row)\n  \n    return results", "cell_type": "code", "metadata": {"ExecuteTime": {"start_time": "2017-12-03T06:34:08.181909Z", "end_time": "2017-12-03T06:34:08.205614Z"}, "deletable": false}, "outputs": [], "execution_count": null}, {"source": "##  <a id=\"workspaces\"></a>Step 5.Create the workspaces. \nUsing each 'train' part of the folds, we will create 5 workspaces, and hold the workspace ID for each. We don't do testing straight away as each workspace needs time to train. ", "cell_type": "markdown", "metadata": {"run_control": {"frozen": true}, "deletable": false}}, {"source": "workspaces = []\n\ndialog_nodes = [\n    {\n     'dialog_node': 'anything_else',\n     'description': 'Required to stop the endless loop error.',\n     'conditions': 'anything_else',\n     'parent': None, \n     'previous_sibling': None,\n     'output': {'text': {'values': ['OK'], 'selection_policy' : 'sequential'}}, \n     'context': None,\n     'metadata': None,\n     'go_to': None\n    }\n]\n\ni = 0\nfor fold in folds:\n    intents = createIntents(fold['train'])\n    response = conversation.create_workspace(name='Fold {}'.format(i),\n                                         description='K-Fold Testing workspace.',\n                                         language=language,\n                                         intents=intents,\n                                         dialog_nodes=dialog_nodes,\n                                         metadata={}).get_result()\n    workspaces.append(response['workspace_id'])\n    print('Created workspace fold {}: {}'.format(i,response['workspace_id']))\n    i = i + 1", "cell_type": "code", "metadata": {"ExecuteTime": {"start_time": "2017-12-03T06:34:18.492122Z", "end_time": "2017-12-03T06:34:24.725802Z"}, "deletable": false}, "outputs": [], "execution_count": null}, {"source": "## <a id=\"status\"></a>Step 6. Check workspace status. \nBefore you start running the testing, you want to make sure that they are all ready to understand. ", "cell_type": "markdown", "metadata": {"run_control": {"frozen": true}, "deletable": false}}, {"source": "i = 0\nfor workspace in workspaces:\n    response = conversation.get_workspace(workspace_id=workspace, export=False).get_result()\n    print('Fold: {}. Workspace: {}.  Status: {}'.format(i,workspace, response['status']))\n    i = i + 1", "cell_type": "code", "metadata": {"ExecuteTime": {"start_time": "2017-12-03T06:35:42.848806Z", "end_time": "2017-12-03T06:35:48.438669Z"}, "deletable": false}, "outputs": [], "execution_count": null}, {"source": "## <a id=\"runtest\"></a>Step 7. Run the test.\n\n**IMPORTANT!** Do not run the next piece until the status is `Available` for all workspaces above. \n\nNow walk through each workspace and test each fold. Generate a final report, and save test information. ", "cell_type": "markdown", "metadata": {}}, {"source": "import json\nimport time\n\nwsid = 0\ncol_list = [ 'Question', 'Expected Intent', 'Matched', 'Found@',\n            'I1', 'C1', 'I2', 'C2', 'I3', 'C3', 'I4', 'C4', 'I5', 'C5',\n            'I6', 'C6', 'I7', 'C7', 'I8', 'C8', 'I9', 'C9', 'I10', 'C10'\n           ]\n\nfold_results = []\nprint('Running Folds')\n\nfor fold in folds:\n    results = []\n    workspace = workspaces[wsid]\n    test_set = fold['test']\n\n    print('Fold {}. Questions = {}'.format(wsid, len(test_set)))\n\n    counter = 0\n    for t in test_set:\n        question = examples.iloc[t]['example']\n        expected_intent = examples.iloc[t]['intent']\n        \n        msg = {'text': question }\n        \n        if counter % 10 == 0: \n            print('X',end='')\n        else:\n            print('.',end='')\n        counter = counter + 1\n        \n        try: \n            response = conversation.message(workspace_id=workspace, input=msg, alternate_intents=True).get_result()\n        except:\n            print('E', end='')\n            time.sleep(5)\n            try:\n                response = conversation.message(workspace_id=workspace, input=msg, alternate_intents=True).get_result()\n            except:\n                print('E', end='')\n                time.sleep(5)\n                response = conversation.message(workspace_id=workspace, input=msg, alternate_intents=True).get_result()\n                \n        intents = response['intents']\n        \n        found_at = [i for i,_ in enumerate(intents) if _['intent'] == expected_intent]\n        if found_at == []: \n            found_at = ''\n        else:\n            found_at = found_at[0]\n\n        row = { \n                'Question': question,\n                'Expected Intent': expected_intent,\n                'Matched': any(expected_intent in x['intent'] for x in intents),\n                'Found@': found_at,\n              }\n        \n        i = 1\n        for intent in intents:\n            row['I{}'.format(i)] = intent['intent']\n            row['C{}'.format(i)] = intent['confidence']\n            i = i + 1\n        \n        results.append(row)\n    print('')\n    \n    fold_result = pd.DataFrame(results, columns=col_list)\n    fold_result.to_csv('fold{}.csv'.format(wsid))\n    wsid = wsid + 1\n    \nprint('')\nprint('Done')", "cell_type": "code", "metadata": {"ExecuteTime": {"start_time": "2017-12-03T06:37:32.535594Z", "end_time": "2017-12-03T06:39:56.374343Z"}, "deletable": false}, "outputs": [], "execution_count": null}, {"source": "## <a id=\"clean\"></a>Step 8.Clean up. \nWhen all done and you want to remove the workspaces in your test service. ", "cell_type": "markdown", "metadata": {"run_control": {"frozen": true}, "deletable": false}}, {"source": "for workspace in workspaces:\n    response = conversation.delete_workspace(workspace_id=workspace).get_result()\n    print('Deleted: {}'.format(workspace))\n", "cell_type": "code", "metadata": {"ExecuteTime": {"start_time": "2017-12-03T06:41:53.000228Z", "end_time": "2017-12-03T06:41:54.065178Z"}, "deletable": false}, "outputs": [], "execution_count": null}, {"source": "## <a id=\"understanding\"></a>Step 9.Understanding the results you got. \n\nAt this point you will have four csv files called `foldX.csv` (where `X` = `0` to `number_of_folds`). The next step is to load these, and get the average across all folds. \n\nFields in the reports:\n\n---\n\n| Field | Description | \n| :-| :-|\n| Question | The question that was used to test with.     |\n| Expected Intent | The intent that was expected to be returned. |\n| Matched  | This will be `true` if expected intent shows up in the top 10 intents returned. |\n| Found@ | This tells you what position it was found at. 0 = Top. | \n| I**x** | Intent found at recall **x** |\n| C**x** | Confidence of Intent found at recall **x** |\n\n--- \n\nFirst load the reports into memory. For this example, we are only going to bother with the main answer found. For production however, you would also examine the top 5 intents, so as to see why a particular question failed.", "cell_type": "markdown", "metadata": {"run_control": {"frozen": true}, "deletable": false}}, {"source": "reports = [] \n#failures = [] \ndrop_fields = [ 'C2', 'C3','C4','C5','C6','C7','C8','C9','C10',\n                'I2','I3','I4','I5','I6','I7','I8','I9','I10',\n                'Found@', 'Matched'\n              ]\n            \nfor x in range(number_of_folds):\n    df = pd.read_csv('fold{}.csv'.format(x),header=0,index_col=0)\n    df.drop(drop_fields, axis=1, inplace=True)\n    df = df.rename(columns={'Expected Intent': 'true_value', 'I1': 'predicted_value', 'C1': 'confidence'})\n#    dz = df[df['true_value']!= df['predicted_value']]\n    reports.append(df)\n#    failures.append(dz)\n    \n# example\nreports[0].head(10)\n\n#display(failures[0],failures[1],failures[2],failures[3],failures[4])\n", "cell_type": "code", "metadata": {"ExecuteTime": {"start_time": "2017-12-03T08:47:20.311001Z", "end_time": "2017-12-03T08:47:20.356008Z"}, "deletable": false}, "outputs": [], "execution_count": null}, {"source": "Now get the overall details of the reports. These are just some sample metrics. ", "cell_type": "markdown", "metadata": {"run_control": {"frozen": true}, "deletable": false}}, {"source": "records = []\nfor index, report in enumerate(reports):\n    tp = report[report['true_value'] == report['predicted_value']]\n    fp = report[report['true_value'] != report['predicted_value']]\n\n    record = {\n        'Report': 'report {}'.format(index+1),\n        'Total': len(report),\n        'Correct': len(tp),\n        'Incorrect': len(fp),\n        'Accuracy': len(tp) / len(report),\n        'Avg Postive Confidence': tp['confidence'].mean(),\n        'Avg Negative Confidence': fp['confidence'].mean()\n    }\n    records.append(record)\n\ndf = pd.DataFrame(records,\n        columns=['Report','Total','Correct','Incorrect','Accuracy','Avg Postive Confidence', 'Avg Negative Confidence']\n)\n\nrecord = [{ 'Report': 'Total/Average',\n           'Total': df['Total'].sum(),\n           'Correct': df['Correct'].sum(),\n           'Incorrect': df['Incorrect'].sum(),\n           'Accuracy': df['Accuracy'].mean(),\n           'Avg Postive Confidence': df['Avg Postive Confidence'].mean(),\n           'Avg Negative Confidence': df['Avg Negative Confidence'].mean()\n}]\n\ndft = pd.DataFrame(record,\n        columns=['Report','Total','Correct','Incorrect','Accuracy','Avg Postive Confidence', 'Avg Negative Confidence']\n)\n\ndf = df.append(dft)\n\ndf", "cell_type": "code", "metadata": {"ExecuteTime": {"start_time": "2017-12-03T10:45:47.604257Z", "end_time": "2017-12-03T10:45:47.662314Z"}, "deletable": false}, "outputs": [], "execution_count": null}, {"source": "In the report above, the accuracy > 0.7 is a good result. The accuracy of correct answers is high, while for wrong answers is lower (could be a little better).", "cell_type": "markdown", "metadata": {}}, {"source": "## <a id=\"matrix\"></a>Step 10. Building a confusion matrix.\n\nIn this example, we will take the combined results and create a confusion matrix. This will allow us to see where one intent may be interfering with another. \n\nWe start by combining the reports.", "cell_type": "markdown", "metadata": {"run_control": {"frozen": true}, "deletable": false}}, {"source": "df = pd.DataFrame([],columns=['Question','true_value','predicted_value','confidence'])\n\nfor report in reports:\n    df = df.append(report,ignore_index=True)\n", "cell_type": "code", "metadata": {"ExecuteTime": {"start_time": "2017-12-03T11:12:48.406854Z", "end_time": "2017-12-03T11:12:48.414809Z"}, "deletable": false}, "outputs": [], "execution_count": null}, {"source": "For the confusion matrix, we need to specify the fields that are going to be scanned. For this demo, we do this by getting the unique list from the records. ", "cell_type": "markdown", "metadata": {"run_control": {"frozen": true}, "editable": false, "deletable": false}}, {"source": "class_names = examples['intent'].unique()\n\nprint('\\n'.join(class_names))", "cell_type": "code", "metadata": {"ExecuteTime": {"start_time": "2017-12-03T12:08:10.594985Z", "end_time": "2017-12-03T12:08:10.599467Z"}, "editable": false, "deletable": false}, "outputs": [], "execution_count": null}, {"source": "This next piece of code is for creating the confusion matrix, and is taken from <A HREF=\"http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html#sphx-glr-auto-examples-model-selection-plot-confusion-matrix-py\">sckit-learn example</A>.", "cell_type": "markdown", "metadata": {"run_control": {"frozen": true}, "editable": false, "deletable": false}}, {"source": "%matplotlib inline\nimport numpy as np\nimport itertools\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import confusion_matrix\nimport matplotlib as mpl\n\nmpl.rcParams['figure.figsize'] = (10,10)\n\ndef plot_confusion_matrix(cm, classes=None,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    thresh = cm.max() / 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, cm[i, j],\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')", "cell_type": "code", "metadata": {"ExecuteTime": {"start_time": "2017-12-03T12:25:18.960539Z", "end_time": "2017-12-03T12:25:18.997787Z"}, "editable": false, "deletable": false}, "outputs": [], "execution_count": null}, {"source": "This last piece of code will display the confusion matrix. ", "cell_type": "markdown", "metadata": {"run_control": {"frozen": true}, "editable": false, "deletable": false}}, {"source": "cm_true = df['true_value'].tolist()\ncm_predicted = df['predicted_value'].tolist()\ncnf_matrix = confusion_matrix(cm_true, cm_predicted,labels=class_names)\n\nnp.set_printoptions(precision=2)\n\nplt.figure(figsize=(15,15))\nplot_confusion_matrix(cnf_matrix, classes=class_names, title='Confusion matrix')\nplt.show()\n\n#plt.figure(figsize=(15,15))\n#plot_confusion_matrix(cnf_matrix, classes=class_names, normalize=True, title='Normalized Confusion matrix')\n#plt.show()", "cell_type": "code", "metadata": {"ExecuteTime": {"start_time": "2017-12-03T12:25:19.989951Z", "end_time": "2017-12-03T12:25:20.382179Z"}, "deletable": false}, "outputs": [], "execution_count": null}, {"source": "## Summary and next steps\nYou've learned how to use the Watson Assistant API to train and evaluate the service. Try adding your own user questions and intents data and see how Watson does!\n\nLearn more:\n- <a href=\"https://www.ibm.com/watson/developercloud/assistant/api/v1/\" target=\"_blank\" rel=\"noopener noreferrer\">Watson Assistant API reference</a>\n- <a href=\"https://github.com/watson-developer-cloud/python-sdk\" target=\"_blank\" rel=\"noopener noreferrer\">Watson Assistant Python SDK</a>\n\n### Authors\nLaurent Vincent.", "cell_type": "markdown", "metadata": {}}], "metadata": {"kernelspec": {"display_name": "Python 3.5", "name": "python3", "language": "python"}, "language_info": {"mimetype": "text/x-python", "nbconvert_exporter": "python", "version": "3.5.5", "name": "python", "pygments_lexer": "ipython3", "file_extension": ".py", "codemirror_mode": {"version": 3, "name": "ipython"}}, "celltoolbar": "Edit Metadata"}, "nbformat": 4}